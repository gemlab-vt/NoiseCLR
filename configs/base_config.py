save_steps = 100 # How frequent to save
pretrained_model = "runwayml/stable-diffusion-v1-5" # Pretrained model signature or path
tokenizer_name = None # If using a different tokenizer
train_data_dir = "input-dataset-path-here" # Path to training data
placeholder_token_count = 100 # Number of directions to learn
initializer_tokens = "" # If provided initializing tokens from these
repeats = 1 # How many times to repeat the training data
output_dir = "outputs/directions" # Output diretory
seed = 0 # For reproducable experiments
center_crop = False
train_batch_size = 6 # Per GPU
tokens_per_iter = 20
num_train_iters = 1000
gradient_accumulation_steps = 4
gradient_checkpointing = True
scale_lr = True
lr_scheduler = "constant" # ["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"]
lr_warmup_steps = 500
resolution = 512
adam_beta1 = 0.9
adam_beta2 = 0.999
adam_weight_decay = 1e-2
adam_epsilon = 1e-08
learning_rate = 1e-3
temperature = 0.5
logging_dir = "logs"
mixed_precision = "no"
resume_from_checkpoint = None
resume_dir = None
normalize_word = False
enable_xformers_memory_efficient_attention = True
validation_step = 100
center_crop = False
subtract_uncond = True
checkpointing_steps = 100